{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter out a certain event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all dataframes (already filtered for the news channels except for the channel dataframe)\n",
    "filtered_df_vid = pl.read_csv(\"./../data/filtered_yt_metadata_helper.feather.csv\")\n",
    "df_ch = pl.read_csv(\"./../data/df_channels_en.tsv\", separator='\\t')\n",
    "filtered_df_ch = df_ch.filter(pl.col(\"category_cc\") == \"News & Politics\")\n",
    "filtered_df_timeseries = pl.read_csv(\"./../data/filtered_df_timeseries_en.tsv\", separator='\\t')\n",
    "num_comments = pl.read_csv(\"./../data/num_comments.tsv\", separator='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename channel_id columns to all have the same name\n",
    "filtered_df_ch = filtered_df_ch.rename({'channel':'channel_id'})\n",
    "filtered_df_timeseries = filtered_df_timeseries.rename({'channel':'channel_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the high activity channels\n",
    "#56 => 4 videos a day\n",
    "grouped_df = filtered_df_timeseries.group_by('channel_id').agg(pl.col('activity').mean().alias('mean_activity'))\n",
    "high_activity_channels = filtered_df_ch.filter(pl.col(\"channel_id\").is_in(grouped_df.filter(pl.col(\"mean_activity\")>56)[\"channel_id\"]))\n",
    "high_activity_channels = high_activity_channels.join(grouped_df, on=\"channel_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter the dataframes to keep the high frequency channels\n",
    "filtered_df_vid = filtered_df_vid.filter(pl.col('channel_id').is_in(high_activity_channels['channel_id']))\n",
    "filtered_df_ch = filtered_df_ch.filter(pl.col('channel_id').is_in(high_activity_channels['channel_id']))\n",
    "filtered_df_timeseries = filtered_df_timeseries.filter(pl.col('channel_id').is_in(high_activity_channels['channel_id']))\n",
    "num_comments = num_comments.filter(pl.col('display_id').is_in(filtered_df_vid['display_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out videos not tagged News and Politics\n",
    "filtered_df_vid = filtered_df_vid.filter(pl.col('categories') == 'News & Politics')\n",
    "filtered_df_ch = filtered_df_ch.filter(pl.col('category_cc') == 'News & Politics')\n",
    "filtered_df_timeseries = filtered_df_timeseries.filter(pl.col('category') == 'News & Politics')\n",
    "filtered_num_comments = num_comments.filter(pl.col('display_id').is_in(filtered_df_vid['display_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter by date\n",
    "min_date = pl.datetime(2017,1,1)\n",
    "max_date = pl.datetime(2018,1,1)\n",
    "\n",
    "filtered_df_timeseries = filtered_df_timeseries.with_columns(pl.col('datetime').str.to_datetime())\n",
    "filtered_df_vid = filtered_df_vid.with_columns(pl.col('upload_date').str.to_datetime())\n",
    "\n",
    "filtered_df_timeseries = filtered_df_timeseries.filter((pl.col('datetime') >= min_date) & (pl.col('datetime') <= max_date))\n",
    "filtered_df_vid = filtered_df_vid.filter((pl.col('upload_date') >= min_date) & (pl.col('upload_date') <= max_date))\n",
    "filtered_df_ch = filtered_df_ch.filter(pl.col('channel_id').is_in(filtered_df_vid['channel_id']))\n",
    "filtered_num_comments = num_comments.filter(pl.col('display_id').is_in(filtered_df_vid['display_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionnary to more easily navigate between channel name and channel id\n",
    "channel_dict = dict(df_ch[['name_cc','channel']].iter_rows())\n",
    "inv_channel_dict = {v: k for k, v in channel_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare channels\n",
    "    - this channels videos, have these characteristics, or perform well with these subjects\n",
    "### General statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get general statistics for all channel on a given column\n",
    "\n",
    "vid_count, vid_mean, vid_std, vid_med = get_general_ch_statistics(filtered_df_vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ttest : checks the null hypothesis that two independant channels have an identical mean number of views, likes etc...\n",
    "# used to compare if two sample's means differ significantly or not\n",
    "\n",
    "ttest_between_two_channels(filtered_df_vid, channel_dict['ABC News'],channel_dict[\"CNN\"], 'like_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F test : test for the null hypothesis that two channels have the same variance\n",
    "# used to compare if two sample's variance differ significantly or not\n",
    "\n",
    "Ftest_between_two_channels(filtered_df_vid, channel_dict['ABC News'],channel_dict[\"CNN\"], 'view_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_video_variables_for_video_dataset(filtered_df_vid, channel_dict['CNN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare two channels normalized by size (number of subscribers, number of views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df_vid = normalize_vids_with_timeseries(filtered_df_vid, filtered_df_timeseries, 'subs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_between_two_channels(normalized_df_vid, channel_dict['ABC News'],channel_dict[\"CNN\"], 'view_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ftest_between_two_channels(normalized_df_vid, channel_dict['ABC News'],channel_dict[\"CNN\"], 'view_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare timeseries data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_count, ts_mean, ts_std, ts_med = get_general_ch_statistics(filtered_df_timeseries,cols_to_keep=['views', 'delta_views', 'subs','delta_subs','videos','delta_videos','activity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_between_two_channels(filtered_df_timeseries, channel_dict['ABC News'],channel_dict[\"CNN\"], 'activity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ftest_between_two_channels(filtered_df_timeseries, channel_dict['ABC News'],channel_dict[\"CNN\"], 'activity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify holes in the data\n",
    "    - channels that donâ€™t report for specific events\n",
    "    - videos with too few comments (under 50 it is not in the comment dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets for first event\n",
    "timeseries_1 = filtered_df_timeseries\n",
    "videos_1 = filtered_df_vid\n",
    "num_comments_1 = filtered_num_comments\n",
    "channels_1 = filtered_df_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets for second event\n",
    "timeseries_2 = filtered_df_timeseries\n",
    "videos_2 = filtered_df_vid\n",
    "num_comments_2 = filtered_num_comments\n",
    "channels_2 = filtered_df_ch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Channels that don't report on both events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channels that report on event1 but not on event2\n",
    "channels_1.filter(~pl.col('channel_id').is_in(channels_2['channel_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channels that report on event2 but not on event1\n",
    "channels_2.filter(~pl.col('channel_id').is_in(channels_1['channel_id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering out videos with too few comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the videos with too few comments can be excluded by filtering\n",
    "too_few_comments = filtered_num_comments.filter(pl.col('num_comms') < 100) #100 is an arbitrary choice\n",
    "\n",
    "#videos with not enough comments\n",
    "filtered_df_vid.filter(pl.col('display_id').is_in(too_few_comments['display_id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare between kinds of events and where events are from\n",
    "    - how many videos\n",
    "    - how many views\n",
    "    - interactions: likes, comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse each event by channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute general statistics for each event\n",
    "\n",
    "vid_count_1, vid_mean_1, vid_std_1, vid_med_1 = get_general_ch_statistics(videos_1)\n",
    "vid_count_2, vid_mean_2, vid_std_2, vid_med_2 = get_general_ch_statistics(videos_2)\n",
    "\n",
    "ts_count_1, ts_mean_1, ts_std_1, ts_med_1 = get_general_ch_statistics(timeseries_1,['views', 'delta_views', 'subs','delta_subs','videos','delta_videos','activity'])\n",
    "ts_count_2, ts_mean_2, ts_std_2, ts_med_2 = get_general_ch_statistics(timeseries_2,['views', 'delta_views', 'subs','delta_subs','videos','delta_videos','activity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_video_variables_for_video_dataset(videos_1, channel_dict['CNN'])\n",
    "plot_video_variables_for_video_dataset(videos_2, channel_dict['CNN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare average number of videos per channel between two events\n",
    "ttest_between_events(vid_count_1['counts'], vid_count_2['counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare variance of the number of videos per channel between two events\n",
    "Ftest_between_events(vid_count_1['counts'], vid_count_2['counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare average number of subscribers gained per channel on videos of a given event\n",
    "ttest_between_events(ts_mean_1['delta_subs'], ts_mean_2['delta_subs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare variance of the number subscribers gained per channel on videos of a given event\n",
    "Ftest_between_events(ts_mean_1['delta_subs'], ts_mean_2['delta_subs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse each event by videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_means,v_stdevs,v_medians = get_general_vid_statistics(filtered_df_vid)\n",
    "v_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_between_events(videos_1['view_count'], videos_2['view_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many comments have replies in each video\n",
    "    - See distributions across different channels/topics\n",
    "    - LET JEFF KNOW IF YOU NEED HELP WITH THIS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
