{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "from analysis_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter out a certain event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all dataframes (already filtered for the news channels except for the channel dataframe)\n",
    "filtered_df_vid = pl.read_csv(\"./../data/filtered_yt_metadata_helper.feather.csv\")\n",
    "df_ch = pl.read_csv(\"./../data/df_channels_en.tsv\", separator='\\t')\n",
    "filtered_df_ch = df_ch.filter(pl.col(\"category_cc\") == \"News & Politics\")\n",
    "filtered_df_timeseries = pl.read_csv(\"./../data/filtered_df_timeseries_en.tsv\", separator='\\t')\n",
    "num_comments = pl.read_csv(\"./../data/num_comments.tsv\", separator='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename channel id columns to all have the same name\n",
    "filtered_df_ch = filtered_df_ch.rename({'channel':'channel_id'})\n",
    "filtered_df_timeseries = filtered_df_timeseries.rename({'channel':'channel_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter by date\n",
    "min_date = pl.datetime(2017,1,1)\n",
    "max_date = pl.datetime(2018,1,1)\n",
    "\n",
    "filtered_df_timeseries = filtered_df_timeseries.with_columns(pl.col('datetime').str.to_datetime())\n",
    "filtered_df_vid = filtered_df_vid.with_columns(pl.col('upload_date').str.to_datetime())\n",
    "\n",
    "filtered_df_timeseries = filtered_df_timeseries.filter((pl.col('datetime') >= min_date) & (pl.col('datetime') <= max_date))\n",
    "filtered_df_vid = filtered_df_vid.filter((pl.col('upload_date') >= min_date) & (pl.col('upload_date') <= max_date))\n",
    "filtered_df_ch = filtered_df_ch.filter(pl.col('channel_id').is_in(filtered_df_vid['channel_id']))\n",
    "filtered_num_comments = num_comments.filter(pl.col('display_id').is_in(filtered_df_vid['display_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionnary to more easily navigate between channel name and channel id\n",
    "channel_dict = dict(df_ch[['name_cc','channel']].iter_rows())\n",
    "inv_channel_dict = {v: k for k, v in channel_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify holes in the data\n",
    "    - channels that donâ€™t report for specific events\n",
    "    - videos with too few comments (under 50 it is not in the comment dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets for first event\n",
    "timeseries_1 = filtered_df_timeseries\n",
    "videos_1 = filtered_df_vid\n",
    "num_comments_1 = filtered_num_comments\n",
    "channels_1 = filtered_df_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets for second event\n",
    "timeseries_2 = filtered_df_timeseries\n",
    "videos_2 = filtered_df_vid\n",
    "num_comments_2 = filtered_num_comments\n",
    "channels_2 = filtered_df_ch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking for channels that do not report on certain events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channels that report on event1 but not on event2\n",
    "channels_1.filter(~pl.col('channel_id').is_in(channels_2['channel_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channels that report on event2 but not on event1\n",
    "channels_2.filter(~pl.col('channel_id').is_in(channels_1['channel_id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering out videos with too few comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the videos with too few comments can be excluded by filtering\n",
    "comment_threshold = 100\n",
    "\n",
    "too_few_comments = filtered_num_comments.filter(pl.col('num_comms') < comment_threshold) #100 is an arbitrary choice\n",
    "\n",
    "#videos with not enough comments\n",
    "filtered_df_vid.filter(pl.col('display_id').is_in(too_few_comments['display_id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare channels\n",
    "    - this channels videos, have these characteristics, or perform well with these subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Channels with correlated video performances (view count, likes, dislikes, number of comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get general statistics for all channel\n",
    "#gives information on the general performance characteristics of the videos from each channel\n",
    "grouped_vids = filtered_df_vid.join(filtered_num_comments, on='display_id')\n",
    "vid_count, vid_mean, vid_std, vid_med = get_general_ch_statistics(grouped_vids, cols_to_keep=['dislike_count','like_count','view_count','num_comms','duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = plot_covariance (vid_mean.drop('duration'),'Covariance matrix between channels', 'Histogram of covariances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrolated_channels = get_correlated_channels(vid_mean,1e10)\n",
    "corrolated_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Channels with correlated video characteristics (length, key words?, ...)\n",
    "\n",
    "##### !!! Note : Keyword analysis has not been added yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = plot_covariance(vid_mean.drop(['num_comms','like_count','dislike_count','view_count']), 'Covariance matrix', 'Histogram of covariances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_correlated_channels(vid_mean.drop(['num_comms','like_count','dislike_count','view_count']), 1e10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More in depth comparaison between two given channels\n",
    "\n",
    "Optional procedure to analyse more in depth the relation between two channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Based on video dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ttest : checks the null hypothesis that two independant channels have an identical mean number of views, likes etc...\n",
    "# used to compare if two sample's means differ significantly or not\n",
    "\n",
    "ttest_between_two_channels(grouped_vids, channel_dict['ABC News'],channel_dict[\"CNN\"], 'num_comms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F test : test for the null hypothesis that two channels have the same variance\n",
    "# used to compare if two sample's variance differ significantly or not\n",
    "\n",
    "Ftest_between_two_channels(grouped_vids, channel_dict['ABC News'],channel_dict[\"CNN\"], 'num_comms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_video_characteristics_for_given_channel(grouped_vids, channel_dict['CNN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Based on timeseries dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_count, ts_mean, ts_std, ts_med = get_general_ch_statistics(filtered_df_timeseries,cols_to_keep=['views', 'delta_views', 'subs','delta_subs','videos','delta_videos','activity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_between_two_channels(filtered_df_timeseries, channel_dict['ABC News'],channel_dict[\"CNN\"], 'activity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ftest_between_two_channels(filtered_df_timeseries, channel_dict['ABC News'],channel_dict[\"CNN\"], 'activity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare channel's video performance when normalized by size (number of subscribers or number of views)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalize by subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df_vid = normalize_vids_with_timeseries(filtered_df_vid, filtered_df_timeseries, 'subs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get general statistics for all channel\n",
    "#gives information on the general performance characteristics of the videos from each channel\n",
    "grouped_vids = normalized_df_vid.join(filtered_num_comments, on='display_id')\n",
    "vid_count, vid_mean, vid_std, vid_med = get_general_ch_statistics(grouped_vids, cols_to_keep=['dislike_count','like_count','view_count','num_comms','duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = plot_covariance (vid_mean.drop('duration'),'Covariance matrix between channels normalized by subscribers', 'Histogram of covariances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrolated_channels = get_correlated_channels(vid_mean,25000)\n",
    "corrolated_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalize by views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df_vid = normalize_vids_with_timeseries(filtered_df_vid, filtered_df_timeseries, 'views')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get general statistics for all channel\n",
    "#gives information on the general performance characteristics of the videos from each channel\n",
    "grouped_vids = normalized_df_vid.join(filtered_num_comments, on='display_id')\n",
    "vid_count, vid_mean, vid_std, vid_med = get_general_ch_statistics(grouped_vids, cols_to_keep=['dislike_count','like_count','view_count','num_comms','duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = plot_covariance (vid_mean.drop('duration'),'Covariance matrix between channels normalized by views', 'Histogram of covariances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrolated_channels = get_correlated_channels(vid_mean,25000)\n",
    "corrolated_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare channel performance across events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets for first event\n",
    "timeseries_1 = filtered_df_timeseries\n",
    "videos_1 = filtered_df_vid\n",
    "num_comments_1 = filtered_num_comments\n",
    "channels_1 = filtered_df_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets for second event\n",
    "timeseries_2 = filtered_df_timeseries\n",
    "videos_2 = filtered_df_vid\n",
    "num_comments_2 = filtered_num_comments\n",
    "channels_2 = filtered_df_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate general statistics for both events\n",
    "grouped_vids_1 = videos_1.join(num_comments_1, on='display_id')\n",
    "vid_count_1, vid_mean_1, vid_std_1, vid_med_1 = get_general_ch_statistics(grouped_vids_1, cols_to_keep=['dislike_count','like_count','view_count','num_comms'])\n",
    "\n",
    "grouped_vids_2 = videos_2.join(num_comments_2, on='display_id')\n",
    "vid_count_2, vid_mean_2, vid_std_2, vid_med_2 = get_general_ch_statistics(grouped_vids_2, cols_to_keep=['dislike_count','like_count','view_count','num_comms'])\n",
    "\n",
    "\n",
    "ts_count_1, ts_mean_1, ts_std_1, ts_med_1 = get_general_ch_statistics(timeseries_1,cols_to_keep=['views', 'delta_views', 'subs','delta_subs','videos','delta_videos','activity'])\n",
    "ts_count_2, ts_mean_2, ts_std_2, ts_med_2 = get_general_ch_statistics(timeseries_2,cols_to_keep=['views', 'delta_views', 'subs','delta_subs','videos','delta_videos','activity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare general channel performance between multiple events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = vid_mean_1.mean()\n",
    "df_2 = vid_mean_2.mean()\n",
    "\n",
    "event_performance = pl.concat([df_1,df_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Covariance matrix for the channel performance to identify channels that perform similarly for a given event.\n",
    "cov = plot_covariance(event_performance,'Covariance across the mean performance of all channels for different events','Histogram of the covariance between events')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare a given channel statistic between two events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ttest : checks the null hypothesis that a given parameter has the same mean across between two events\n",
    "# used to compare if two means differ significantly or not\n",
    "\n",
    "ttest_between_events(ts_mean_1['activity'], ts_mean_2['activity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ftest : checks the null hypothesis that a given parameter has the same variance across between two events\n",
    "# used to compare if two means differ significantly or not\n",
    "\n",
    "Ftest_between_events(ts_mean_1['activity'], ts_mean_2['activity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare between kinds of events and where events are from\n",
    "    - how many videos\n",
    "    - how many views\n",
    "    - interactions: likes, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute general statistics for each event\n",
    "\n",
    "vid_count_1, vid_mean_1, vid_std_1, vid_med_1 = get_general_ch_statistics(videos_1)\n",
    "vid_count_2, vid_mean_2, vid_std_2, vid_med_2 = get_general_ch_statistics(videos_2)\n",
    "\n",
    "ts_count_1, ts_mean_1, ts_std_1, ts_med_1 = get_general_ch_statistics(timeseries_1,['views', 'delta_views', 'subs','delta_subs','videos','delta_videos','activity'])\n",
    "ts_count_2, ts_mean_2, ts_std_2, ts_med_2 = get_general_ch_statistics(timeseries_2,['views', 'delta_views', 'subs','delta_subs','videos','delta_videos','activity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare number of videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare number of videos between two events\n",
    "\n",
    "compare_overall_vid_count_between_events(vid_count_1, vid_count_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare average number of videos per channel between two events\n",
    "ttest_between_events(vid_count_1['counts'], vid_count_2['counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare variance of the number of videos per channel between two events\n",
    "Ftest_between_events(vid_count_1['counts'], vid_count_2['counts'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse each event by videos (number of views, number of likes/dislikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_means_1,v_stdevs_1,v_medians_1 = get_general_vid_statistics(videos_1)\n",
    "v_means_2,v_stdevs_2,v_medians_2 = get_general_vid_statistics(videos_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.concat([v_means_1,v_means_2]).insert_column(0,pl.Series(['event_1','event_2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_video_statistics_between_events(videos_1,videos_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_between_events(videos_1['view_count'], videos_2['view_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many comments have replies in each video\n",
    "    - See distributions across different channels/topics\n",
    "    - LET JEFF KNOW IF YOU NEED HELP WITH THIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
